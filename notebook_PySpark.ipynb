{
"cells": [

{
      "cell_type": "markdown",
      "metadata": {
        "id": "4ae6fd90ce34"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b690120659f"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ]
    },
   {
      "cell_type": "markdown",
      "metadata": {
        "id": "98ca9d3da7e6"
      },
      "source": [
        "### Create a Cloud Storage bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ead6150209c"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
        "REGION = \"[your-region]\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "933efba860bc"
      },
      "outputs": [],
      "source": [
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
        "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26fd8d22e96f"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d201bf34f895"
      },
      "outputs": [],
      "source": [
        "! gsutil mb -l $REGION $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f62553e5054"
      },
      "source": [
        "**Finally**, validate access to your Cloud Storage bucket by examining its contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73f53d17ae47"
      },
      "outputs": [],
      "source": [
        "! gsutil ls -al $BUCKET_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ef78f6261a0"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "The ALS model approach is compute-intensive and could take a lot of time to train on a regular notebook environment, so this tutorial uses a Dataproc cluster with PySpark environment.\n",
        "\n",
        "### Create a Dataproc cluster with component gateway enabled and JupyterLab extension\n",
        "<a name=\"section-5\"></a>\n",
        "\n",
        "Create the cluster using the following `gcloud` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "950554272656"
      },
      "outputs": [],
      "source": [
        "CLUSTER_NAME = \"[your-cluster-name]\"\n",
        "CLUSTER_REGION = \"[your-cluster-region]\"\n",
        "CLUSTER_ZONE = \"[your-cluster-zone]\"\n",
        "MACHINE_TYPE = \"[your=machine-type]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e3e719e27f6"
      },
      "outputs": [],
      "source": [
        "! gcloud dataproc clusters create $CLUSTER_NAME \\\n",
        "--enable-component-gateway \\\n",
        "--region $CLUSTER_REGION \\\n",
        "--zone $CLUSTER_ZONE \\\n",
        "--single-node \\\n",
        "--master-machine-type $MACHINE_TYPE \\\n",
        "--master-boot-disk-size 100 \\\n",
        "--image-version 2.0-debian10 \\\n",
        "--optional-components JUPYTER \\\n",
        "--project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b864144904fb"
      },
      "source": [
        "## Connect to the cluster from the notebook\n",
        "<a name=\"section-6\"></a>\n",
        "\n",
        "When the new Dataproc cluster is running, the corresponding runtime appears as a kernel in the notebook. The created cluster's name will appear in the list of kernels that can be selected for this notebook. In the top right corner of this notebook file, click the current kernel name, **Python (local)**, and then select the Python 3 kernel that is running on your Dataproc cluster.\n",
        "\n",
        "<img src=\"images/cluster_kernel_selection.png\"></img>\n",
        "\n",
        "Note the following:\n",
        "\n",
        "- Your Dataproc kernel might take a few minutes to show up in the list of kernels.\n",
        "- PySpark code in this tutorial can be run on either a PySpark or Python 3 kernel on the Dataproc cluster, but to run the optional code that saves recommendations to a BigQuery table, the Python 3 kernel is recommended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4abc4fb13e25"
      },
      "source": [
        "#@bigquery\n",
        "#TODO#Change this to our view query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba1a54b04d9a"
      },
      "outputs": [],
      "source": [
        "# The following two lines are only necessary to run once.\n",
        "# Comment out otherwise for speed-up.\n",
        "from google.cloud.bigquery import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "query = \"\"\"WITH user_prod_table AS (\n",
        "SELECT USER_ID, PRODUCT_ID, STATUS FROM looker-private-demo.retail.order_items AS a\n",
        "join\n",
        "(SELECT ID, PRODUCT_ID FROM looker-private-demo.retail.inventory_items) AS b\n",
        "on a.inventory_item_id = b.ID )\n",
        "\n",
        "SELECT USER_ID, PRODUCT_ID, STATUS from user_prod_table\"\"\"\n",
        "job = client.query(query)\n",
        "df = job.to_dataframe()"
      ]
    }
    









],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
